{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dependencies import *\n",
    "import os\n",
    "import igraph\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "import implicit\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(data, user='user', retweeted_user='in_reply_to_screen_name'):\n",
    "    graph = {}\n",
    "    \n",
    "    for i in data.index:\n",
    "        if data.loc[i][retweeted_user] != None:\n",
    "            if data.loc[i][user]['screen_name'] not in list(graph.keys()):\n",
    "                graph[data.loc[i][user]['screen_name']] = [data.loc[i][retweeted_user]]\n",
    "            elif data.loc[i][retweeted_user] not in graph[data.loc[i][user]['screen_name']]:\n",
    "                graph[data.loc[i][user]['screen_name']].append(data.loc[i][retweeted_user])\n",
    "            else:\n",
    "                continue\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_graph(data)\n",
    "g = igraph.Graph()\n",
    "g.add_vertices(list(set(list(graph.keys()) + list([a for value in graph.values() for a in value]))))\n",
    "g.add_edges([(key, value) for key in graph.keys() for value in graph[key]])\n",
    "\n",
    "print('Nodes: {}\\nEdges: {}'.format(len(g.vs), len(g.es)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 11074\n",
      "Edges: 7678\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split trian/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "p = 0.2\n",
    "N = len(g.es)\n",
    "all_idxs = range(N)\n",
    "test_ids = np.random.choice(a = all_idxs, size = int(p*N), replace=False)\n",
    "aux = g.copy()\n",
    "aux.delete_vertices(test_ids)\n",
    "\n",
    "print('Nodes: {}\\nEdges: {}'.format(len(aux.vs), len(aux.es)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 9539\n",
      "Edges: 5799\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendations(graph):\n",
    "    \"\"\"\n",
    "    starting from a graph this function returns all the nodes at distance 2\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    all_potential_recommendations = set()\n",
    "    \n",
    "    for n1 in graph.vs:\n",
    "        \n",
    "        # all the nodes at distance 1\n",
    "        nodes_at_most_distant_1 = set(graph.neighborhood(vertices = n1, order = 1))\n",
    "\n",
    "        # all the nodes at distance 1 and distance 2\n",
    "        nodes_at_most_distant_2 = set(graph.neighborhood(vertices = n1, order = 2))\n",
    "        \n",
    "        # only the nodes at distance 2\n",
    "        only_nodes_at_distance_2 = nodes_at_most_distant_2 - nodes_at_most_distant_1\n",
    "        \n",
    "        \n",
    "        # check if empty set\n",
    "        if len(only_nodes_at_distance_2) > 0:\n",
    "            \n",
    "\n",
    "            for n2 in only_nodes_at_distance_2:\n",
    "                \n",
    "                # since n1 is an igraph vertex object, we need to extract the id\n",
    "                n1_index = n1.index\n",
    "                \n",
    "                all_potential_recommendations.add((n1_index, n2))\n",
    "            \n",
    "    return all_potential_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_k(g, topk, vid=None):\n",
    "        \n",
    "    pr = enumerate(g.personalized_pagerank(reset_vertices=vid))\n",
    "    out = sorted(pr, key=lambda tup: tup[1], reverse=True)[:topk]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = set()\n",
    "trainset = set()\n",
    "for idx, one_edge in enumerate(g.es):\n",
    "    n1 = one_edge.source\n",
    "    n2 = one_edge.target\n",
    "    \n",
    "    if idx in test_ids:\n",
    "        ground_truth.add((n1, n2, 1))\n",
    "    else:\n",
    "        trainset.add((n1, n2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_potential_recommendations = recomendations(aux)\n",
    "for rec in all_potential_recommendations:\n",
    "    n1 = rec[0]\n",
    "    n2 = rec[1]\n",
    "    ground_truth.add((n1,n2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9758671749472292"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topkppr = {}\n",
    "topk = 1\n",
    "for node in test_ids:\n",
    "    topkppr[node] = print_top_k(g, 1, vid=node)[0][0]\n",
    "ppr_df = pd.DataFrame({'node':list(topkppr.keys()), 'recommendation': list(topkppr.values())})\n",
    "for i in ppr_df.index:\n",
    "    if ppr_df.loc[i]['node'] == ppr_df.loc[i]['recommendation']:\n",
    "        ppr_df = ppr_df.drop(i)\n",
    "\n",
    "df_test = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "l = []\n",
    "for i in df_test.index:\n",
    "    for j in ppr_df.index:\n",
    "        if df_test.loc[i]['n1'] == ppr_df.loc[j]['node'] and df_test.loc[i]['n2'] == ppr_df.loc[j]['recommendation']:\n",
    "            l.append(1)\n",
    "        else:\n",
    "            l.append(0)\n",
    "            break\n",
    "\n",
    "df_test['rating'] = l\n",
    "\n",
    "right_predictions = len(df_test[df_test['rating']==df_test['edge']])\n",
    "right_predictions/len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e48f75ed9b343f3b63f34237ec701b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9774739296178444"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "M = g.get_adjacency().data\n",
    "M = csr_matrix(M)\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=10, calculate_training_loss=True,  iterations=5)\n",
    "model.fit(M)\n",
    "\n",
    "df_test = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "all_predictions = []\n",
    "\n",
    "for n1,n2, w in df_test.values:\n",
    "    array_n1 = model.user_factors[n1,:]\n",
    "    array_n2 = model.item_factors[n2,:]\n",
    "    one_p = np.dot(array_n1, array_n2)\n",
    "    all_predictions.append(one_p)\n",
    "\n",
    "\n",
    "df_test[\"rating\"] = all_predictions\n",
    "df_test[\"rating\"] = df_test[\"rating\"].apply(lambda x: round(x))\n",
    "\n",
    "right_predictions = len(df_test[df_test['rating']==df_test['edge']])\n",
    "right_predictions/len(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
